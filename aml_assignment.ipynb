{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HumeraF2/AML-Assignment/blob/main/aml_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqSXUvESqEGx",
        "outputId": "09773372-84f1-4d27-e074-10482231d1d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpIDrgQCb-8V"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceDFkrFzcEGU"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data/credit_card_churn.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fontb_CFcbYc"
      },
      "outputs": [],
      "source": [
        "print(df.info(),'\\n')\n",
        "print(df.head(),'\\n')\n",
        "print(df.describe(),'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fk2b-TQoPaCO"
      },
      "outputs": [],
      "source": [
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5Uz2NuM-OYG"
      },
      "outputs": [],
      "source": [
        "#Check for missing values\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwxh5tF3pJLU"
      },
      "outputs": [],
      "source": [
        "#Calculate summary statistics for categorical data\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    print(f\"{col}:\\n{df[col].value_counts()}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eY_Va35Mph7g"
      },
      "outputs": [],
      "source": [
        "#Drop unnecessary features\n",
        "df.drop(['CLIENTNUM','Marital_Status', 'Education_Level'], axis=1, inplace=True)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Display Multiple Boxplots to identify any outliers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "columns = ['Customer_Age', 'Months_on_book','Total_Revolving_Bal','Credit_Limit','Avg_Open_To_Buy','Total_Trans_Amt', 'Total_Trans_Ct']\n",
        "for col in columns:\n",
        "  plt.boxplot(df[col],vert=False)\n",
        "  plt.title(col)\n",
        "  plt.ylabel(col)\n",
        "  plt.rcParams[\"figure.figsize\"] = (3,2)\n",
        "  plt.show()\n",
        " "
      ],
      "metadata": {
        "id": "VTh9L7nnGvBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awSk_vXWc2ti"
      },
      "outputs": [],
      "source": [
        "#** Removing Outliers: To remove outliers, use a method like Z-score or IQR to detect and remove the extreme values. **\n",
        "from scipy import stats\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Calculate Z-scores and retain rows with Z-score greater than -3 or less than +3\n",
        "\n",
        "z_scores = stats.zscore(df['Customer_Age'])\n",
        "plt.boxplot(z_scores,vert=False)\n",
        "df = df[(z_scores >= -3) & (z_scores <= 3)]\n",
        "plt.title('Box plot of Age')\n",
        "plt.ylabel('Customer_Age')\n",
        "plt.rcParams[\"figure.figsize\"] = (3,2)\n",
        "plt.show()\n",
        "\n",
        "z_scores = stats.zscore(df['Months_on_book'])\n",
        "plt.boxplot(z_scores,vert=False)\n",
        "df = df[(z_scores >= -3) & (z_scores <= 3)]\n",
        "plt.title('Box plot of Months_on_book')\n",
        "plt.ylabel('Months on Book')\n",
        "plt.show()\n",
        "\n",
        "z_scores = stats.zscore(df['Total_Trans_Ct'])\n",
        "plt.boxplot(z_scores,vert=False)\n",
        "df = df[(z_scores >= -3) & (z_scores <= 3)]\n",
        "plt.title('Box plot of Total Transaction Ct')\n",
        "plt.ylabel('Total Transaction Ct')\n",
        "plt.show()\n",
        "\n",
        "z_scores = stats.zscore(df['Credit_Limit'])\n",
        "plt.boxplot(z_scores,vert=False)\n",
        "df = df[(z_scores >= -3) & (z_scores <= 3)]\n",
        "plt.title('Box plot of Credit Limit')\n",
        "plt.ylabel('Credit Limit')\n",
        "plt.show()\n",
        "\n",
        "z_scores = stats.zscore(df['Avg_Open_To_Buy'])\n",
        "plt.boxplot(z_scores,vert=False)\n",
        "df = df[(z_scores >= -3) & (z_scores <= 3)]\n",
        "plt.title('Box plot of Avg Open To Buy')\n",
        "plt.ylabel('Avg Open To Buy')\n",
        "plt.show()\n",
        "\n",
        "z_scores = stats.zscore(df['Total_Trans_Amt'])\n",
        "plt.boxplot(z_scores,vert=False)\n",
        "df = df[(z_scores >= -3) & (z_scores <= 3)]\n",
        "plt.title('Box plot of Total Transanction Amt')\n",
        "plt.ylabel('Total Transanction Amt')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the box plot again\n",
        "\n",
        "columns = ['Customer_Age', 'Months_on_book','Credit_Limit','Avg_Open_To_Buy','Total_Trans_Amt', 'Total_Trans_Ct']\n",
        "for col in columns:\n",
        "  plt.boxplot(df[col],vert=False)\n",
        "  plt.title(col)\n",
        "  plt.ylabel(col)\n",
        "  plt.rcParams[\"figure.figsize\"] = (3,2)\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "fmMZRN84Xul1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKcXGsVLkSoM"
      },
      "outputs": [],
      "source": [
        "#Convert the categorical variables to dummy variables\n",
        "df = pd.get_dummies(df, drop_first=False)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EttDE8CdudpJ"
      },
      "outputs": [],
      "source": [
        "df.drop(['Attrition_Flag_Attrited Customer','Income_Category_Unknown', 'Card_Category_Silver'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTLNdeHbk9Cn"
      },
      "outputs": [],
      "source": [
        "#Standardisation\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "  \n",
        "# Separate the dummy variables from the numerical variables\n",
        "dummy_cols = df.select_dtypes(include='uint8').columns\n",
        "num_cols = list(set(df.select_dtypes(include=['float64', 'int64']).columns) - set(dummy_cols))\n",
        "\n",
        "# Standardize the numerical variables\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "\n",
        "# Combine the standardized numerical variables with the dummy variables\n",
        "df_std = pd.concat([df[num_cols], df[dummy_cols]], axis=1)\n",
        "\n",
        "print(df_std.head(5),'\\n')\n",
        "print(df_std.describe(),'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8U6Y3yGnkehb"
      },
      "outputs": [],
      "source": [
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJC_KHjs9c-j"
      },
      "outputs": [],
      "source": [
        "#Split the data into training and test sets (70:30)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_std.drop('Attrition_Flag_Existing Customer', axis=1), df['Attrition_Flag_Existing Customer'], test_size=0.3, random_state=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbf94XotmOEp"
      },
      "outputs": [],
      "source": [
        "#Import/install the necessary packages\n",
        "!pip install scikeras\n",
        "import scikeras as sk\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "from scikeras.wrappers import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESWFF9dTmall"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense (21, input_dim=X_train.shape[1], activation='relu'))\n",
        "    model.add(Dense(15, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    return model   \n",
        "\n",
        "# create the model\n",
        "model = KerasRegressor(build_fn=create_model, verbose=0, )\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nF4lVwamo7v"
      },
      "outputs": [],
      "source": [
        "# define the grid search parameters\n",
        "param_grid = {'batch_size': [32, 64],\n",
        "              'epochs': [50,100],\n",
        "              'optimizer': ['adam', 'sgd']}\n",
        "\n",
        "\n",
        "# perform grid search to find the best hyperparameters\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        " \n",
        "# print the best parameters\n",
        "print(f\"Best Parameters: {grid_result.best_params_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtwj7z6FmpxL"
      },
      "outputs": [],
      "source": [
        "#Fit the model with the best hyperparameters and make predictions using the test set\n",
        "best_model = grid.best_estimator_\n",
        "best_model.fit(X_train, y_train, epochs=grid_result.best_params_['epochs'], batch_size=grid_result.best_params_['batch_size'], verbose=0, callbacks=[EarlyStopping(patience=10, restore_best_weights=True)])\n",
        "\n",
        "# Y predict on X test set\n",
        "y_pred = best_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHgaXArNm5OS"
      },
      "outputs": [],
      "source": [
        "#Display Feature Importance\n",
        "\n",
        "importance = best_model.predict(X_train, verbose=0)\n",
        "importance = np.squeeze(importance)\n",
        "feature_names = X_train.columns\n",
        "feature_importance = dict(zip(feature_names, importance))\n",
        "sorted_importance = sorted(feature_importance.items(), key=lambda kv: abs(kv[1]), reverse=True)\n",
        "\n",
        "for feature, importance in sorted_importance:\n",
        "    print(f\"{feature}: {abs(importance)}\")\n",
        "\n",
        "importance_values = [abs(kv[1]) for kv in sorted_importance]\n",
        "#print(importance_values)\n",
        "feature_names = [kv[0] for kv in sorted_importance]\n",
        "#print(feature_names)\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
        "plt.barh(range(len(importance_values)), importance_values, align='center')\n",
        "plt.yticks(range(len(feature_names)), feature_names)\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMG76Sn_12Iq"
      },
      "outputs": [],
      "source": [
        "#predict the churn values\n",
        "print(y_pred)\n",
        "# unscaling the y_pred values \n",
        "y_pred_lis = []\n",
        "for i in y_pred:\n",
        "    if i>0.5:\n",
        "        y_pred_lis.append(1)\n",
        "    else:\n",
        "        y_pred_lis.append(0)\n",
        "print(y_pred_lis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOXKfMK42z7G"
      },
      "outputs": [],
      "source": [
        "#make dataframe for comparing the orignal and predict values\n",
        "data = {'orignal_churn':y_test, 'predicted_churn':y_pred_lis}\n",
        "df_check = pd.DataFrame(data)\n",
        "df_check.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz2PTKVS3r0q"
      },
      "outputs": [],
      "source": [
        "# checking for performance metrices, importing classification_report and confusion metrics\n",
        "import seaborn as sb\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "#print classification_report\n",
        "print(classification_report(y_test, y_pred_lis))\n",
        "\n",
        "# ploting the confusion metrix plot\n",
        "conf_mat = tf.math.confusion_matrix(labels=y_test,predictions=y_pred_lis)\n",
        "plt.figure(figsize = (10,5))\n",
        "sb.heatmap(conf_mat, annot=True,fmt='d',)\n",
        "plt.xlabel('Predicted_number')\n",
        "plt.ylabel('True_number')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ru3AtIQDaTtT"
      },
      "outputs": [],
      "source": [
        "#Roc and auc curves\n",
        "from sklearn import metrics\n",
        "auc = metrics.roc_auc_score(y_test, y_pred)\n",
        "false_positive_rate, true_positive_rate, thresolds = metrics.roc_curve(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6, 4), dpi=100)\n",
        "plt.axis('scaled')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.title(\"AUC & ROC Curve\")\n",
        "plt.plot(false_positive_rate, true_positive_rate, 'g')\n",
        "plt.fill_between(false_positive_rate, true_positive_rate, facecolor='lightgreen', alpha=0.7)\n",
        "plt.text(0.95, 0.05, 'AUC = %0.4f' % auc, ha='right', fontsize=12, weight='bold', color='blue')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRoACrTruNX+Hsy00KPUZ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}